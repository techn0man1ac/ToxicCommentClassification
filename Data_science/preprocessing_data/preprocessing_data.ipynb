{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1735833341630,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "NBgWi6wcjFN8",
    "outputId": "4c580677-be61-48fe-a77c-4ae4795156c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
      "unzip:  cannot find or open jigsaw-toxic-comment-classification-challenge.zip, jigsaw-toxic-comment-classification-challenge.zip.zip or jigsaw-toxic-comment-classification-challenge.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install kaggle\n",
    "!unzip jigsaw-toxic-comment-classification-challenge.zip\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1735833517456,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "ol_HxC2KjLJz",
    "outputId": "aad0a75a-feb2-4f5c-ecb9-bf3a45e2d552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file train.csv has been successfully extracted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "# Load the dataset\n",
    "if not os.path.exists('train.csv'):\n",
    "    if os.path.exists('train.csv.zip'):\n",
    "        with zipfile.ZipFile('train.csv.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall()\n",
    "        print(\"The file train.csv has been successfully extracted.\")\n",
    "    else:\n",
    "        print(\"The file train.csv or train.csv.zip was not found.\")\n",
    "else:\n",
    "    print(\"The file train.csv already exists in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1735830850635,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "8rgNITZHrGN8"
   },
   "outputs": [],
   "source": [
    "# # Information of the dataset\n",
    "# data = pd.read_csv('train.csv')\n",
    "# print(\"\\nDataset information:\")\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1735833524819,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "FG5rtkf2jLSe",
    "outputId": "5dede5f7-301c-4512-e64b-f3aa18f62a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution among classes and without labels:\n",
      "Class          Count          Percentage\n",
      "----------------------------------------\n",
      "toxic          15294          9.58      %\n",
      "severe_toxic   1595           1.00      %\n",
      "obscene        8449           5.29      %\n",
      "threat         478            0.30      %\n",
      "insult         7877           4.94      %\n",
      "identity_hate  1405           0.88      %\n",
      "Non-toxic      143346         89.83     %\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "# Defining class columns\n",
    "class_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Calculating the number of labels in each class\n",
    "class_counts = data[class_columns].sum()\n",
    "\n",
    "# Analyzing comments with no labels\n",
    "no_labels_count = (data[class_columns].sum(axis=1) == 0).sum()\n",
    "\n",
    "# Calculating percentage distribution\n",
    "total_comments = len(data)\n",
    "class_percentages = class_counts / total_comments * 100\n",
    "no_labels_percentage = no_labels_count / total_comments * 100\n",
    "\n",
    "# Formatted output\n",
    "print(\"Distribution among classes and without labels:\")\n",
    "print(f\"{'Class':<15}{'Count':<15}{'Percentage':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for label, count in class_counts.items():\n",
    "    percentage = class_percentages[label]\n",
    "    print(f\"{label:<15}{count:<15}{percentage:<10.2f}%\")\n",
    "print(f\"{'Non-toxic':<15}{no_labels_count:<15}{no_labels_percentage:<10.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1735833530846,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "OxG-9Fl7rkO3"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11411,
     "status": "ok",
     "timestamp": 1735833544575,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "zb8fK7ebjLb_",
    "outputId": "f8e7dd93-95af-480c-928f-8e57c8c1293e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "\n",
      "Cleaned text:\n",
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text for use with BERT\n",
    "def clean_text_for_bert(text):\n",
    "    # Remove newline characters\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove time in the format HH:MM\n",
    "    text = re.sub(r'\\b\\d{1,2}:\\d{2}\\b', '', text)\n",
    "    # Remove dates.\n",
    "    text = re.sub(r'\\b\\d{4}[-/\\.]\\d{2}[-/\\.]\\d{2}\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d{2}[-/\\.]\\d{2}[-/\\.]\\d{4}\\b', '', text)\n",
    "    # Remove IP addresses\n",
    "    text = re.sub(r'\\b\\d{1,3}(?:\\.\\d{1,3}){3}\\b', '', text)\n",
    "    return text\n",
    "\n",
    "# Create a new column for cleaned data\n",
    "data['cleaned_comment_text_for_bert'] = data['comment_text'].apply(clean_text_for_bert)\n",
    "# Check the result\n",
    "print(\"Original text:\")\n",
    "print(data['comment_text'].iloc[0])\n",
    "print(\"\\nCleaned text:\")\n",
    "print(data['cleaned_comment_text_for_bert'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6292,
     "status": "ok",
     "timestamp": 1735833550853,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "W6gzSWIVrjUw",
    "outputId": "1fae4d75-9f18-477f-da60-e6a491066a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "!pip install transformers torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1735833777820,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "3hvmHepJsAW2",
    "outputId": "84f7fa24-5bb4-4485-b808-25494fe456f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define the class columns\n",
    "class_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Add a column that indicates whether a comment is toxic (1 - toxic, 0 - non-toxic)\n",
    "data['is_toxic'] = (data[class_columns].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# Split features and labels\n",
    "X = data['cleaned_comment_text_for_bert'].values.reshape(-1, 1)\n",
    "y = data['is_toxic'].values\n",
    "\n",
    "# Perform undersampling of non-toxic (0) to match the level of toxic (1)\n",
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Create a DataFrame with undersampled comments\n",
    "balanced_data = pd.DataFrame(X_resampled, columns=['cleaned_comment_text_for_bert'])\n",
    "balanced_data['is_toxic'] = y_resampled\n",
    "\n",
    "# Restore the original labels for each comment\n",
    "for col in class_columns:\n",
    "    balanced_data[col] = 0\n",
    "    balanced_data.loc[balanced_data['is_toxic'] == 1, col] = data.loc[data['is_toxic'] == 1, col].values\n",
    "\n",
    "# Remove the temporary column\n",
    "balanced_data.drop(columns=['is_toxic'], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1735833849935,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "TgQevU2i4l5_",
    "outputId": "85d11af9-d407-4002-c51a-f96d64fb2b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution among classes in balanced_data:\n",
      "Class          Count          Percentage\n",
      "----------------------------------------\n",
      "toxic          15294          47.13     %\n",
      "severe_toxic   1595           4.92      %\n",
      "obscene        8449           26.04     %\n",
      "threat         478            1.47      %\n",
      "insult         7877           24.27     %\n",
      "identity_hate  1405           4.33      %\n",
      "Non-toxic      16225          50.00     %\n"
     ]
    }
   ],
   "source": [
    "# Checking class distribution in balanced_data\n",
    "class_counts_balanced = balanced_data[class_columns].sum()\n",
    "no_labels_count_balanced = (balanced_data[class_columns].sum(axis=1) == 0).sum()\n",
    "\n",
    "# Calculating percentage distribution\n",
    "total_comments_balanced = len(balanced_data)\n",
    "class_percentages_balanced = class_counts_balanced / total_comments_balanced * 100\n",
    "no_labels_percentage_balanced = no_labels_count_balanced / total_comments_balanced * 100\n",
    "\n",
    "# Displaying results\n",
    "print(\"Distribution among classes in balanced_data:\")\n",
    "print(f\"{'Class':<15}{'Count':<15}{'Percentage':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for label, count in class_counts_balanced.items():\n",
    "    percentage = class_percentages_balanced[label]\n",
    "    print(f\"{label:<15}{count:<15}{percentage:<10.2f}%\")\n",
    "print(f\"{'Non-toxic':<15}{no_labels_count_balanced:<15}{no_labels_percentage_balanced:<10.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1735409188910,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "6nGeWeFxA6wA",
    "outputId": "741343f6-4f53-4f47-fad3-5263eadd90e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість коментарів після undersampling: 31825\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# # Визначення класів\n",
    "# class_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# # 1. Визначаємо non-toxic коментарі (мітки == 0 по всіх класах)\n",
    "# non_toxic_mask = (data[class_columns].sum(axis=1) == 0)  # non-toxic якщо сума == 0\n",
    "# X_non_toxic = data.loc[non_toxic_mask, 'cleaned_comment_text_for_bert'].values\n",
    "# y_non_toxic = data.loc[non_toxic_mask, class_columns].values\n",
    "\n",
    "# # 2. Зменшуємо кількість non-toxic коментарів до 15600\n",
    "# num_samples = 15600\n",
    "# if len(X_non_toxic) > num_samples:\n",
    "#     indices = np.random.choice(len(X_non_toxic), num_samples, replace=False)\n",
    "#     X_non_toxic_resampled = X_non_toxic[indices]\n",
    "#     y_non_toxic_resampled = y_non_toxic[indices]\n",
    "# else:\n",
    "#     X_non_toxic_resampled = X_non_toxic\n",
    "#     y_non_toxic_resampled = y_non_toxic\n",
    "\n",
    "# # 3. Створюємо DataFrame з undersampled non-toxic коментарями\n",
    "# balanced_non_toxic = pd.DataFrame(X_non_toxic_resampled, columns=['cleaned_comment_text_for_bert'])\n",
    "# balanced_non_toxic[class_columns] = y_non_toxic_resampled\n",
    "\n",
    "# # 4. Об'єднуємо збалансовані non-toxic з усіма іншими коментарями (токсичними та non-toxic)\n",
    "# balanced_data = pd.concat([\n",
    "#     balanced_non_toxic,        # undersampled non-toxic\n",
    "#     data[~non_toxic_mask]      # всі токсичні коментарі та non-toxic, які залишилися\n",
    "# ])\n",
    "\n",
    "# # 5. Скидання індексації\n",
    "# balanced_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(f\"Кількість коментарів після undersampling: {balanced_data.shape[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2920,
     "status": "ok",
     "timestamp": 1735833927977,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "P4hwMxpeUTGa",
    "outputId": "ef3604c9-67fa-4d2f-f872-a5d5ebc6d6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlpaug\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.16.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
      "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nlpaug\n",
      "Successfully installed nlpaug-1.1.11\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2588,
     "status": "ok",
     "timestamp": 1735834611404,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "P3j_aD7LU0Ny",
    "outputId": "0bf146ca-2a10-4937-e2e1-f31d5911240d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nltk\n",
    "# nltk.download('all')\n",
    "\n",
    "# Download necessary NLTK packages\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "# Create synonym augmenter\n",
    "syn_aug = naw.SynonymAug(aug_src='wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1735834141947,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "bze10T9qtPOI",
    "outputId": "c1486ba3-8262-48a9-e8f9-5ab07db960d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Analysis for class 'toxic':\n",
      "Only toxic: 5666\n",
      "toxic + other labels: 9628\n",
      "Label combinations:\n",
      "toxic            9628\n",
      "obscene          7926\n",
      "insult           7344\n",
      "severe_toxic     1595\n",
      "identity_hate    1302\n",
      "threat            449\n",
      "dtype: int64\n",
      "\n",
      " Analysis for class 'severe_toxic':\n",
      "Only severe_toxic: 0\n",
      "severe_toxic + other labels: 1595\n",
      "Label combinations:\n",
      "toxic            1595\n",
      "severe_toxic     1595\n",
      "obscene          1517\n",
      "insult           1371\n",
      "identity_hate     313\n",
      "threat            112\n",
      "dtype: int64\n",
      "\n",
      " Analysis for class 'obscene':\n",
      "Only obscene: 317\n",
      "obscene + other labels: 8132\n",
      "Label combinations:\n",
      "obscene          8132\n",
      "toxic            7926\n",
      "insult           6155\n",
      "severe_toxic     1517\n",
      "identity_hate    1032\n",
      "threat            301\n",
      "dtype: int64\n",
      "\n",
      " Analysis for class 'threat':\n",
      "Only threat: 22\n",
      "threat + other labels: 456\n",
      "Label combinations:\n",
      "threat           456\n",
      "toxic            449\n",
      "insult           307\n",
      "obscene          301\n",
      "severe_toxic     112\n",
      "identity_hate     98\n",
      "dtype: int64\n",
      "\n",
      " Analysis for class 'insult':\n",
      "Only insult: 301\n",
      "insult + other labels: 7576\n",
      "Label combinations:\n",
      "insult           7576\n",
      "toxic            7344\n",
      "obscene          6155\n",
      "severe_toxic     1371\n",
      "identity_hate    1160\n",
      "threat            307\n",
      "dtype: int64\n",
      "\n",
      " Analysis for class 'identity_hate':\n",
      "Only identity_hate: 54\n",
      "identity_hate + other labels: 1351\n",
      "Label combinations:\n",
      "identity_hate    1351\n",
      "toxic            1302\n",
      "insult           1160\n",
      "obscene          1032\n",
      "severe_toxic      313\n",
      "threat             98\n",
      "dtype: int64\n",
      "\n",
      " Class distribution analysis:\n",
      "               Total  Single Class  Multi-label\n",
      "toxic          15294          5666         9628\n",
      "severe_toxic    1595             0         1595\n",
      "obscene         8449           317         8132\n",
      "threat           478            22          456\n",
      "insult          7877           301         7576\n",
      "identity_hate   1405            54         1351\n",
      "\n",
      " Percentage of multi-label comments for each class:\n",
      "               Multi-label %\n",
      "toxic              62.952792\n",
      "severe_toxic      100.000000\n",
      "obscene            96.248077\n",
      "threat             95.397490\n",
      "insult             96.178748\n",
      "identity_hate      96.156584\n"
     ]
    }
   ],
   "source": [
    "# 1. Count the number of comments in each class\n",
    "class_counts = balanced_data[class_columns].sum()\n",
    "\n",
    "# 2. Analyze comments that belong to only one class\n",
    "single_class_counts = {}\n",
    "multi_label_counts = {}\n",
    "\n",
    "for label in class_columns:\n",
    "    # Select comments where only one class = 1, and others = 0\n",
    "    single_class = balanced_data[(balanced_data[label] == 1) & (balanced_data[class_columns].sum(axis=1) == 1)]\n",
    "    single_class_counts[label] = len(single_class)\n",
    "\n",
    "    # Select comments where the label is part of a multilabel\n",
    "    multi_class = balanced_data[(balanced_data[label] == 1) & (balanced_data[class_columns].sum(axis=1) > 1)]\n",
    "    multi_label_counts[label] = len(multi_class)\n",
    "\n",
    "    # Analyze other labels for multilabel\n",
    "    print(f\"\\n Analysis for class '{label}':\")\n",
    "    print(f\"Only {label}: {len(single_class)}\")\n",
    "    print(f\"{label} + other labels: {len(multi_class)}\")\n",
    "    if len(multi_class) > 0:\n",
    "        print(\"Label combinations:\")\n",
    "        print(multi_class[class_columns].sum().sort_values(ascending=False))\n",
    "\n",
    "# 3. Output the summary table\n",
    "analysis_df = pd.DataFrame({\n",
    "    'Total': class_counts,\n",
    "    'Single Class': pd.Series(single_class_counts),\n",
    "    'Multi-label': pd.Series(multi_label_counts)\n",
    "})\n",
    "\n",
    "# 4. Display results\n",
    "print(\"\\n Class distribution analysis:\")\n",
    "print(analysis_df)\n",
    "\n",
    "# Percentage of multi-label comments for each class\n",
    "analysis_df['Multi-label %'] = (analysis_df['Multi-label'] / analysis_df['Total']) * 100\n",
    "\n",
    "print(\"\\n Percentage of multi-label comments for each class:\")\n",
    "print(analysis_df[['Multi-label %']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1735834212509,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "lLdwvkXNxlwZ",
    "outputId": "6a0adbe9-cbc4-4f16-8d6f-a0c78abfc615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Relationship matrix between classes (number of comments):\n",
      "               toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "toxic          15294          1595     7926     449    7344           1302\n",
      "severe_toxic    1595          1595     1517     112    1371            313\n",
      "obscene         7926          1517     8449     301    6155           1032\n",
      "threat           449           112      301     478     307             98\n",
      "insult          7344          1371     6155     307    7877           1160\n",
      "identity_hate   1302           313     1032      98    1160           1405\n",
      "\n",
      " Relationship matrix between classes (percentages):\n",
      "                toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "toxic          100.00        100.00    93.81   93.93   93.23          92.67\n",
      "severe_toxic    10.43        100.00    17.95   23.43   17.41          22.28\n",
      "obscene         51.82         95.11   100.00   62.97   78.14          73.45\n",
      "threat           2.94          7.02     3.56  100.00    3.90           6.98\n",
      "insult          48.02         85.96    72.85   64.23  100.00          82.56\n",
      "identity_hate    8.51         19.62    12.21   20.50   14.73         100.00\n"
     ]
    }
   ],
   "source": [
    "# 1. Count the total number of comments in each class\n",
    "total_class_counts = balanced_data[class_columns].sum()\n",
    "\n",
    "# 2. Initialize a DataFrame to store the relationships between classes\n",
    "relation_matrix = pd.DataFrame(0, index=class_columns, columns=class_columns)\n",
    "\n",
    "# 3. Analyze relationships between classes\n",
    "for label in class_columns:\n",
    "    # Select all comments that belong to the class label\n",
    "    class_data = balanced_data[balanced_data[label] == 1]\n",
    "\n",
    "    # Count the number of comments that also belong to other classes\n",
    "    relation_counts = class_data[class_columns].sum()\n",
    "\n",
    "    # Fill in the relationship matrix (excluding itself)\n",
    "    relation_matrix.loc[label] = relation_counts\n",
    "\n",
    "# 4. Normalize for relationships (in percentage)\n",
    "relation_percentage = (relation_matrix.div(total_class_counts, axis=1) * 100).round(2)\n",
    "\n",
    "# 5. Display results\n",
    "print(\" Relationship matrix between classes (number of comments):\")\n",
    "print(relation_matrix)\n",
    "\n",
    "print(\"\\n Relationship matrix between classes (percentages):\")\n",
    "print(relation_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23110,
     "status": "ok",
     "timestamp": 1735834671441,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "PFcUFzhShwJQ",
    "outputId": "892bbe83-1ecb-4b11-b1c5-3f9fd78c71bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Кількість severe_toxic до аугментації: 1595\n",
      "\n",
      "Кількість threat до аугментації: 478\n",
      "\n",
      "Кількість identity_hate до аугментації: 1405\n",
      "\n",
      "Added 9346 new comments.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import resample\n",
    "# import nlpaug.augmenter.word as naw\n",
    "# import pandas as pd\n",
    "\n",
    "# Initialize the synonym augmenter\n",
    "syn_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "# Text augmentation function\n",
    "def augment_text(text, n=1):\n",
    "    augmented_texts = [text]\n",
    "    for _ in range(n):\n",
    "        augmented_texts.append(syn_aug.augment(text))\n",
    "    return augmented_texts\n",
    "\n",
    "# 1. First augmentation for severe_toxic, threat, identity_hate\n",
    "\n",
    "augmented_rows = []\n",
    "\n",
    "for label in ['severe_toxic', 'threat', 'identity_hate']:\n",
    "    class_data = balanced_data[balanced_data[label] == 1]\n",
    "    print(f\"\\nNumber of {label} before augmentation: {len(class_data)}\")\n",
    "\n",
    "    n = 6 if label == 'threat' else 1\n",
    "\n",
    "    for _, row in class_data.iterrows():\n",
    "        augmented_comments = augment_text(row['cleaned_comment_text_for_bert'], n=n)\n",
    "\n",
    "        for comment in augmented_comments:\n",
    "            augmented_rows.append({\n",
    "                'cleaned_comment_text_for_bert': comment,\n",
    "                'toxic': 0,\n",
    "                'severe_toxic': row['severe_toxic'],\n",
    "                'obscene': row['obscene'],\n",
    "                'threat': row['threat'],\n",
    "                'insult': row['insult'],\n",
    "                'identity_hate': row['identity_hate']\n",
    "            })\n",
    "\n",
    "# 2. Create DataFrame and merge\n",
    "\n",
    "if augmented_rows:\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    balanced_data = pd.concat([balanced_data, augmented_df], ignore_index=True)\n",
    "    print(f\"\\nAdded {len(augmented_df)} new comments.\")\n",
    "else:\n",
    "    print(\"Augmentation did not create new texts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1735834687281,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "Raa1qys2mcJo",
    "outputId": "0ec9e69b-f92d-4eb8-b464-f2505d160195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Розподіл класів після аугментації:\n",
      "toxic            15294\n",
      "severe_toxic      6195\n",
      "obscene          15654\n",
      "threat            4244\n",
      "insult           15088\n",
      "identity_hate     5527\n",
      "dtype: int64\n",
      "\n",
      "Shape of balanced_data after augmentation: (41796, 7)\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\nРозподіл класів після аугментації:\")\n",
    "# print(balanced_data[class_columns].sum())\n",
    "# print(\"\\nShape of balanced_data after augmentation:\", balanced_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1735835438484,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "deY8YsZWF4No",
    "outputId": "2f206702-b16d-4cf1-cc2f-ab70dc6a1241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution among classes in balanced_data:\n",
      "Class          Count          Percentage\n",
      "----------------------------------------\n",
      "toxic          15294          36.59     %\n",
      "severe_toxic   6195           14.82     %\n",
      "obscene        15654          37.45     %\n",
      "threat         4244           10.15     %\n",
      "insult         15088          36.10     %\n",
      "identity_hate  5527           13.22     %\n",
      "Non-toxic      16225          38.82     %\n"
     ]
    }
   ],
   "source": [
    "# Checking class distribution in balanced_data\n",
    "class_counts_balanced = balanced_data[class_columns].sum()\n",
    "no_labels_count_balanced = (balanced_data[class_columns].sum(axis=1) == 0).sum()\n",
    "\n",
    "# Calculating percentage distribution\n",
    "total_comments_balanced = len(balanced_data)\n",
    "class_percentages_balanced = class_counts_balanced / total_comments_balanced * 100\n",
    "no_labels_percentage_balanced = no_labels_count_balanced / total_comments_balanced * 100\n",
    "\n",
    "# Displaying results\n",
    "print(\"Distribution among classes in balanced_data:\")\n",
    "print(f\"{'Class':<15}{'Count':<15}{'Percentage':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for label, count in class_counts_balanced.items():\n",
    "    percentage = class_percentages_balanced[label]\n",
    "    print(f\"{label:<15}{count:<15}{percentage:<10.2f}%\")\n",
    "print(f\"{'Non-toxic':<15}{no_labels_count_balanced:<15}{no_labels_percentage_balanced:<10.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42496,
     "status": "ok",
     "timestamp": 1735835660697,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "ib7fp1nIfjvy",
    "outputId": "3ccb89ac-e523-402d-a854-dfdc6cdf3a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added 26082 new comments (with zeroing of other classes).\n",
      "\n",
      "Class distribution after second augmentation:\n",
      "toxic            15294\n",
      "severe_toxic     15500\n",
      "obscene          15654\n",
      "threat           12732\n",
      "insult           15088\n",
      "identity_hate    13816\n",
      "dtype: int64\n",
      "\n",
      "Shape of balanced_data after second augmentation: (67878, 7)\n",
      "\n",
      "Number of new augmented comments by class:\n",
      "severe_toxic     9305\n",
      "threat           8488\n",
      "identity_hate    8289\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "augmented_rows_second = []\n",
    "\n",
    "for label in ['severe_toxic', 'threat', 'identity_hate']:\n",
    "    class_data = balanced_data[balanced_data[label] == 1]\n",
    "\n",
    "    for _, row in class_data.iterrows():\n",
    "        # Set augmentation probabilities for each class\n",
    "        if label in ['severe_toxic', 'identity_hate']:\n",
    "            n = np.random.choice([0, 1], p=[0.5, 0.5])\n",
    "        else:\n",
    "            n = 1\n",
    "\n",
    "        # Perform text augmentation\n",
    "        augmented_comments = augment_text(row['cleaned_comment_text_for_bert'], n=n)\n",
    "\n",
    "        for comment in augmented_comments:\n",
    "            augmented_rows_second.append({\n",
    "                'cleaned_comment_text_for_bert': comment,\n",
    "                'toxic': 0,\n",
    "                'severe_toxic': 1 if label == 'severe_toxic' else 0,\n",
    "                'obscene': 0,\n",
    "                'threat': 1 if label == 'threat' else 0,\n",
    "                'insult': 0,\n",
    "                'identity_hate': 1 if label == 'identity_hate' else 0\n",
    "            })\n",
    "\n",
    "# Create DataFrame from augmented texts\n",
    "if augmented_rows_second:\n",
    "    augmented_df_second = pd.DataFrame(augmented_rows_second)\n",
    "    balanced_data = pd.concat([balanced_data, augmented_df_second], ignore_index=True)\n",
    "    print(f\"\\nAdded {len(augmented_df_second)} new comments (with zeroing of other classes).\")\n",
    "else:\n",
    "    print(\"Augmentation did not create new texts.\")\n",
    "\n",
    "\n",
    "# Count after the second augmentation\n",
    "\n",
    "print(\"\\nClass distribution after second augmentation:\")\n",
    "print(balanced_data[class_columns].sum())\n",
    "print(\"\\nShape of balanced_data after second augmentation:\", balanced_data.shape)\n",
    "\n",
    "# Output the number of new comments for each class\n",
    "aug_count = augmented_df_second[['severe_toxic', 'threat', 'identity_hate']].sum()\n",
    "print(\"\\nNumber of new augmented comments by class:\")\n",
    "print(aug_count)\n",
    "\n",
    "# # Check examples of new comments\n",
    "# print(\"\\nSample of augmented comments (second run):\")\n",
    "# print(augmented_df_second[['cleaned_comment_text_for_bert', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1735835676677,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "5vIc8-izTd4c",
    "outputId": "57a7cf7a-f5b7-47cb-9594-f79881d1fb04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution among classes in balanced_data:\n",
      "Class          Count          Percentage\n",
      "----------------------------------------\n",
      "toxic          15294          22.53     %\n",
      "severe_toxic   15500          22.84     %\n",
      "obscene        15654          23.06     %\n",
      "threat         12732          18.76     %\n",
      "insult         15088          22.23     %\n",
      "identity_hate  13816          20.35     %\n",
      "Non-toxic      16225          23.90     %\n"
     ]
    }
   ],
   "source": [
    "# Checking class distribution in balanced_data\n",
    "class_counts_balanced = balanced_data[class_columns].sum()\n",
    "no_labels_count_balanced = (balanced_data[class_columns].sum(axis=1) == 0).sum()\n",
    "\n",
    "# Calculating percentage distribution\n",
    "total_comments_balanced = len(balanced_data)\n",
    "class_percentages_balanced = class_counts_balanced / total_comments_balanced * 100\n",
    "no_labels_percentage_balanced = no_labels_count_balanced / total_comments_balanced * 100\n",
    "\n",
    "# Displaying results\n",
    "print(\"Distribution among classes in balanced_data:\")\n",
    "print(f\"{'Class':<15}{'Count':<15}{'Percentage':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for label, count in class_counts_balanced.items():\n",
    "    percentage = class_percentages_balanced[label]\n",
    "    print(f\"{label:<15}{count:<15}{percentage:<10.2f}%\")\n",
    "print(f\"{'Non-toxic':<15}{no_labels_count_balanced:<15}{no_labels_percentage_balanced:<10.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274,
     "referenced_widgets": [
      "68fd468c8d1b47ec98d06fc5dfa0e94c",
      "0d942dc96f5e44eca912b24bbd893b92",
      "9d1fae4e613c4fdd9b5f8e2e1c204b8d",
      "5cab64706f354495a9785deae6d7b1fe",
      "ee41bd2df44b4bfeac42836f3a724376",
      "4e34889909104e308d816194abea9346",
      "f51ea07c64c54766a84b3938978e5a07",
      "2a1714eaa3a94bdf9e6631946cb36b7c",
      "5bfcc11d5d934015a222ea6a84455962",
      "7cd9048208114248a4a230f918bceb3f",
      "f08732db3ae847079e668d022c0e020a",
      "af6dc479e694450f8af02f8f7df8de0e",
      "4e8a19c791894b70bdd91e94e56c4536",
      "75023271c1f249c0825964e0c4b71019",
      "fa00895734044e1b9f4d46298a971eb6",
      "632a641c07ec4f68b71df78bcd1dc28e",
      "2dd438a8ebe04894b005ef9c53f1a1c7",
      "91d3d0b4b8c04f02bc4101b622da6682",
      "d91bff35eb6c4e93b644e7a1f325703f",
      "869007be9f364ee695728bca23e4834e",
      "1df64e9aac50441296d4beaa41a51f1a",
      "8af375e3ca194c088c83484f34f64131",
      "0e3e7f5f3392420d9dcb4678ae01f284",
      "fcb9e7e274954b4899f173da5b787f81",
      "6bf64cb401bf4917913f82ea0849828d",
      "54d0918ee096430bb3f3b07157a26666",
      "157b48faaca4463286878bdf5ec130c5",
      "a677487bcdf947b9be017445de20ab6e",
      "ebbba26e41da463e903938c6914140eb",
      "78d55eb46c06470a84d96c5b24d466dc",
      "a5f3d1b755a14d0c9da7ed6823805e68",
      "018f631878f44e6e9d587ba985d18cac",
      "b3b42ff0f13d4384b9934caa10fad45e",
      "733a05c56b5b4fc19d4cccd3052c726b",
      "27b7a29eaeab41e283ca24b24a95185a",
      "2293e760ebb3476a9714ac627aa25b26",
      "c89d143fe86a405899e7ebbff5baaf6e",
      "0ec598911c344f248eee8883e655a657",
      "f706a0b6aaa9407aba98a2def4a16c65",
      "058a38795a8440ddb0ed0b396f65427d",
      "3c1d88a8437245209795d509e85f1d84",
      "d88a2524fa6546e8a8a0d40d2deb6543",
      "21adc102abab4cf4b5d1fc682abb96dd",
      "f90432eaa3314c8daabd14dfe987aac1"
     ]
    },
    "executionInfo": {
     "elapsed": 6113,
     "status": "ok",
     "timestamp": 1735835710970,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "wxdE5uLS6OpL",
    "outputId": "d2525c30-f1e0-4742-a538-bc327f6161da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fd468c8d1b47ec98d06fc5dfa0e94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6dc479e694450f8af02f8f7df8de0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3e7f5f3392420d9dcb4678ae01f284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733a05c56b5b4fc19d4cccd3052c726b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1735835741047,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "m_Ir4ARR5Ob6"
   },
   "outputs": [],
   "source": [
    "# Function for tokenizing text using the BERT tokenizer\n",
    "def tokenize_text(text, max_len=128):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoded['input_ids'].squeeze(0), encoded['attention_mask'].squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1735835757503,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "WHKn8mWO6kIq"
   },
   "outputs": [],
   "source": [
    "# Converts label values into a PyTorch tensor\n",
    "def encode_labels(row):\n",
    "    return torch.tensor([row['toxic'], row['severe_toxic'], row['obscene'], row['threat'], row['insult'], row['identity_hate']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1735835788241,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "Sg0h8Skg6ntV"
   },
   "outputs": [],
   "source": [
    "# Function to prepare data for the model\n",
    "def prepare_data(data, max_len=128):\n",
    "    input_ids_list = []\n",
    "    attention_masks_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # Tokenizing the text\n",
    "        input_ids, attention_mask = tokenize_text(row['cleaned_comment_text_for_bert'], max_len)\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_masks_list.append(attention_mask)\n",
    "\n",
    "        # Converting labels\n",
    "        labels = torch.tensor(row[class_columns].astype(int).values)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "\n",
    "     # Creating the final DataFrame\n",
    "    return pd.DataFrame({\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_masks_list,\n",
    "        \"labels\": labels_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122354,
     "status": "ok",
     "timestamp": 1735836277233,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "T4ZksCvB8SRm",
    "outputId": "6ca46c2b-3fbd-4d32-9a05-73b787acd4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           input_ids  \\\n",
      "0  [tensor(101), tensor(1000), tensor(2821), tens...   \n",
      "1  [tensor(101), tensor(2024), tensor(2017), tens...   \n",
      "2  [tensor(101), tensor(25430), tensor(4140), ten...   \n",
      "3  [tensor(101), tensor(3104), tensor(2061), tens...   \n",
      "4  [tensor(101), tensor(1052), tensor(1012), tens...   \n",
      "\n",
      "                                      attention_mask  \\\n",
      "0  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
      "1  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
      "2  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
      "3  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
      "4  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
      "\n",
      "                                              labels  \n",
      "0  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n",
      "1  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n",
      "2  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n",
      "3  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n",
      "4  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n"
     ]
    }
   ],
   "source": [
    "prepared_data = prepare_data(balanced_data, max_len=128)\n",
    "print(prepared_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1735836347639,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "gmIOWpUbaL3n",
    "outputId": "17a82a95-8ee3-4f88-bac6-70053e5ca1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids: torch.Size([67878, 128])\n",
      "Shape of attention_mask: torch.Size([67878, 128])\n",
      "Shape of labels: torch.Size([67878, 6])\n"
     ]
    }
   ],
   "source": [
    "# Convert columns to tensors\n",
    "input_ids_tensor = torch.stack(prepared_data['input_ids'].tolist())\n",
    "attention_mask_tensor = torch.stack(prepared_data['attention_mask'].tolist())\n",
    "labels_tensor = torch.stack(prepared_data['labels'].tolist())\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Shape of input_ids: {input_ids_tensor.shape}\")\n",
    "print(f\"Shape of attention_mask: {attention_mask_tensor.shape}\")\n",
    "print(f\"Shape of labels: {labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3842,
     "status": "ok",
     "timestamp": 1735836735896,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "L6P09XEp6Uky",
    "outputId": "d8d3e827-7cc7-460a-d2db-575baac2c913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'bert_ready_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for BERT processing\n",
    "bert_data = pd.DataFrame({\n",
    "    'input_ids': input_ids_tensor.tolist(),\n",
    "    'attention_mask': attention_mask_tensor.tolist(),\n",
    "    'labels': labels_tensor.tolist()\n",
    "})\n",
    "\n",
    "# Save as CSV format\n",
    "bert_data.to_csv('bert_ready_data2.csv', index=False)\n",
    "print(\"DataFrame saved as 'bert_ready_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1735836427983,
     "user": {
      "displayName": "Аlena Мishchenko",
      "userId": "12740130789596532633"
     },
     "user_tz": -60
    },
    "id": "Yed9zQWY6WbV"
   },
   "outputs": [],
   "source": [
    "# loaded_data = pd.read_csv('bert_ready_data2.csv')\n",
    "# print(loaded_data.head())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO9jtr5CBPhw/3xSeG+mYmm",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "13IhUDmwc_h-DMv3gkW5XHBFzf2BYfGPG",
     "timestamp": 1735836846184
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
